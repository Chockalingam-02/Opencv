# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hbJimYEKSCBKYCGCZrVPB63MW9V3ZoSe
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
img=cv2.imread('/content/sample_data/istockphoto-1208049833-612x612.jpg')
scale_x,scale_y=5,5
img_scale=cv2.resize(img,None,fx=scale_x,fy=scale_y,interpolation=cv2.INTER_LINEAR)
plt.subplot(2,3,1)
plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))
plt.title("Original image")
plt.subplot(2,3,2)
plt.imshow(cv2.cvtColor(img_scale,cv2.COLOR_BGR2RGB))
plt.title("Scaled image")
plt.show()
(h,v) = img.shape[:2]
center = (311,240)
angle = 45
scale =1.0
rotation_matrix = cv2.getRotationMatrix2D(center, angle, scale)
rotated_image = cv2.warpAffine(img, rotation_matrix, (v, h))
plt.imshow(cv2.cvtColor(rotated_image,cv2.COLOR_BGR2RGB))
plt.title("Rotated image")
plt.subplot(2,3,3)
plt.show()
tx,ty = 50,100
translation_matrix = np.array([[1, 0, tx], [0, 1, ty]], dtype=np.float32)
translated_image = cv2.warpAffine(img, translation_matrix, (v, h))
plt.imshow(cv2.cvtColor(translated_image,cv2.COLOR_BGR2RGB))
plt.title("Translated image")
plt.subplot(2,3,4)
pts1=np.float32([[50,50],[200,50],[50,200],[200,200]])
pts2=np.float32([[10,100],[200,50],[100,250],[250,250]])
matrix =cv2.getPerspectiveTransform(pts1,pts2)
img_output=cv2.warpPerspective(img,matrix,(v,h))
plt.imshow(cv2.cvtColor(img_output,cv2.COLOR_BGR2RGB))
plt.title("Perspective image")
plt.subplot(2,3,5)

plt.show()

plt.show()

pip install opencv-python

import cv2
print(cv2.__version__)

import cv2
from google.colab.patches import cv2_imshow
image=cv2.imread('/content/sample_data/istockphoto-1210792722-612x612.jpg')
cv2_imshow(image)
cv2.waitKey(0)
cv2.destroyAllWindows()

cv2.rectangle(image,(50,50),(200,200),(0,255),3)
cv2_imshow(image)

import cv2
from google.colab.patches import cv2_imshow
image=cv2.imread('/content/sample_data/istockphoto-1210792722-612x612.jpg')
cv2_imshow(image)
cv2.circle(image,(311,229),255,(200,20,25),3)
cv2_imshow(image)



import cv2

# Load the image
image = cv2.imread('/content/sample_data/istockphoto-1210792722-612x612.jpg')

# Get the height and width
height, width, channels = image.shape

# Print the height and width
print(f'Height: {height}, Width: {width}')

import cv2
from google.colab.patches import cv2_imshow
image=cv2.imread('/content/sample_data/pexels-quang-nguyen-vinh-222549-2131614.jpg', 0)
_,global_thresh = cv2.threshold(image, 73, 255, cv2.THRESH_BINARY)
cv2_imshow(global_thresh)

adaptive_thresh_Mean=cv2.adaptiveThreshold(image,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,101,2)
cv2_imshow(adaptive_thresh_Mean)

import cv2
from google.colab.patches import cv2_imshow
image=cv2.imread('/content/sample_data/istockphoto-1210792722-612x612.jpg', 0)
adaptive_thresh_gausian = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 2061, 2)
cv2_imshow(adaptive_thresh_gausian)

import cv2
from google.colab.patches import cv2_imshow
image=cv2.imread('/content/sample_data/istockphoto-1210792722-612x612.jpg', 0)
_,otsu_thresh = cv2.threshold(image, 2061, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
cv2_imshow(otsu_thresh)

import cv2
from google.colab.patches import cv2_imshow
import numpy as np
img = cv2.imread('/content/sample_data/istockphoto-1210792722-612x612.jpg')
kernel_size=7; sign=1.5
gaussian_filtered = cv2.GaussianBlur(img, (kernel_size, kernel_size), sign)
cv2_imshow(img)
cv2_imshow(gaussian_filtered)

import cv2
from google.colab.patches import cv2_imshow
image=cv2.imread('/content/sample_data/images.jpg')
cv2_imshow(image)

import cv2
from google.colab.patches import cv2_imshow
import numpy as np
img = cv2.imread('/content/sample_data/istockphoto-1210792722-612x612.jpg')
kernel_size=7; sign=1.5
gaussian_filtered = cv2.GaussianBlur(img, (kernel_size, kernel_size), sign)
cv2_imshow(img)
cv2_imshow(gaussian_filtered)

import cv2
from google.colab.patches import cv2_imshow
img=cv2.imread('/content/sample_data/download (2).jpg')
kernal_size=5
median_filtered=cv2.medianBlur(img,kernal_size)
cv2_imshow(img)
cv2_imshow(median_filtered)
median_filtered2=cv2.medianBlur(median_filtered ,kernel_size)
cv2_imshow(median_filtered2)

import cv2
from google.colab.patches import cv2_imshow
img=cv2.imread('/content/sample_data/download (2).jpg')
d=9; sign_color=255; sign_space=75
bilateral_filtered=cv2.bilateralFilter(img,d,sign_color,sign_space)
cv2_imshow(img)
cv2_imshow(bilateral_filtered)

import cv2
from google.colab.patches import cv2_imshow
img=cv2.imread('/content/sample_data/download (2).jpg')
cv2.rectangle(image,(50,50),(200,200),(0,255),3)
cv2.circle(image,(3976,2652),500,(200,20,25),3)
cv2_imshow(image)

import cv2
from google.colab.patches import cv2_imshow
img=cv2.imread('/content/sample_data/istockphoto-1208049833-612x612.jpg')
sodelx=cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)
cv2_imshow(sodelx)
sodely=cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)
cv2_imshow(sodely)

import cv2
from google.colab.patches import cv2_imshow
img=cv2.imread('/content/sample_data/istockphoto-1208049833-612x612.jpg')
canmy_edge=cv2.Canny(img,100,200)
cv2_imshow(canmy_edge)

11==[11.22,33,44]
12==[1,2,3,4]
import numpy as np
c=np.array(11)
c2=np.array(12)
v=c/c2
v

import cv2
import numpy as np
import matplotlib.pyplot as plt
img=cv2.imread('/content/sample_data/istockphoto-1208049833-612x612.jpg')
from google.colab.patches import cv2_imshow
img=cv2.imread('/content/sample_data/istockphoto-1208049833-612x612.jpg')
img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
plt.imshow(img)
plt.title("original image")
plt.show()

import cv2
import numpy as np
import matplotlib.pyplot as plt
img=cv2.imread('/content/sample_data/istockphoto-1208049833-612x612.jpg')

from google.colab.patches import cv2_imshow
img=cv2.imread('/content/sample_data/istockphoto-1208049833-612x612.jpg')
hight,width,channel=img.shape
print('hight=',hight)
print('width=',width)
print('channel=',channel)

import cv2
import numpy as np
import matplotlib.pyplot as plt
img=cv2.imread('/content/sample_data/istockphoto-1208049833-612x612.jpg')
scale_x,scale_y=5,5
img_scale=cv2.resize(img,None,fx=scale_x,fy=scale_y,interpolation=cv2.INTER_LINEAR)
plt.subplot(1,2,1)
plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))
plt.title("Original image")
plt.subplot(1,2,2)
plt.imshow(cv2.cvtColor(img_scale,cv2.COLOR_BGR2RGB))
plt.title("Scaled image")
plt.show()

(h,v) = img.shape[:2]
center = (v / 2, h / 2)
angle = 500
scale =1.0
rotation_matrix = cv2.getRotationMatrix2D(center, angle, scale)
rotated_image = cv2.warpAffine(img, rotation_matrix, (v, h))
plt.imshow(cv2.cvtColor(rotated_image,cv2.COLOR_BGR2RGB))
plt.title("Rotated image")
plt.show()

(h,v) = img.shape[:2]
center = (311,240)
angle = 45
scale =1.0
rotation_matrix = cv2.getRotationMatrix2D(center, angle, scale)
rotated_image = cv2.warpAffine(img, rotation_matrix, (v, h))
plt.imshow(cv2.cvtColor(rotated_image,cv2.COLOR_BGR2RGB))
plt.title("Rotated image")
plt.show()

tx,ty = 50,100
translation_matrix = np.array([[1, 0, tx], [0, 1, ty]], dtype=np.float32)
translated_image = cv2.warpAffine(img, translation_matrix, (v, h))
plt.imshow(cv2.cvtColor(translated_image,cv2.COLOR_BGR2RGB))
plt.title("Translated image")
plt.show()

tx,ty = -90,-90
translation_matrix = np.array([[1, 0, tx], [0, 1, ty]], dtype=np.float32)
translated_image = cv2.warpAffine(img, translation_matrix, (v, h))
plt.imshow(cv2.cvtColor(translated_image,cv2.COLOR_BGR2RGB))
plt.title("Translated image")
plt.show()

flapped_horizontally = cv2.flip(img, 1)
flapped_vertically = cv2.flip(img, 0)
flapped_both = cv2.flip(img, -1)
plt.subplot(3,2,1)
plt.imshow(cv2.cvtColor(flapped_horizontally,cv2.COLOR_BGR2RGB))
plt.title("Flipped horizontally")
plt.subplot(3,2,2)
plt.imshow(cv2.cvtColor(flapped_vertically,cv2.COLOR_BGR2RGB))
plt.title("Flipped vertically")
plt.subplot(3,2,5)
plt.imshow(cv2.cvtColor(flapped_both,cv2.COLOR_BGR2RGB))
plt.title("Flipped both")
plt.subplot(3,2,6)
plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))
plt.title("Original image")
plt.show()

pts1=np.float32([[50,50],[200,50],[50,200],[200,200]])
pts2=np.float32([[10,100],[200,50],[100,250],[250,250]])
matrix =cv2.getPerspectiveTransform(pts1,pts2)
img_output=cv2.warpPerspective(img,matrix,(v,h))
plt.imshow(cv2.cvtColor(img_output,cv2.COLOR_BGR2RGB))
plt.title("Perspective image")

import cv2
import numpy as np
import matplotlib.pyplot as plt
img=cv2.imread('/content/sample_data/istockphoto-1208049833-612x612.jpg')
scale_x,scale_y=5,5
img_scale=cv2.resize(img,None,fx=scale_x,fy=scale_y,interpolation=cv2.INTER_LINEAR)
plt.subplot(2,3,1)
plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))
plt.title("Original image")
plt.subplot(2,3,2)
plt.imshow(cv2.cvtColor(img_scale,cv2.COLOR_BGR2RGB))
plt.title("Scaled image")
plt.show()
(h,v) = img.shape[:2]
center = (311,240)
angle = 45
scale =1.0
rotation_matrix = cv2.getRotationMatrix2D(center, angle, scale)
rotated_image = cv2.warpAffine(img, rotation_matrix, (v, h))
plt.imshow(cv2.cvtColor(rotated_image,cv2.COLOR_BGR2RGB))
plt.title("Rotated image")
plt.subplot(2,3,3)
plt.show()
tx,ty = 50,100
translation_matrix = np.array([[1, 0, tx], [0, 1, ty]], dtype=np.float32)
translated_image = cv2.warpAffine(img, translation_matrix, (v, h))
plt.imshow(cv2.cvtColor(translated_image,cv2.COLOR_BGR2RGB))
plt.title("Translated image")
plt.subplot(2,3,4)
pts1=np.float32([[50,50],[200,50],[50,200],[200,200]])
pts2=np.float32([[10,100],[200,50],[100,250],[250,250]])
matrix =cv2.getPerspectiveTransform(pts1,pts2)
img_output=cv2.warpPerspective(img,matrix,(v,h))
plt.imshow(cv2.cvtColor(img_output,cv2.COLOR_BGR2RGB))
plt.title("Perspective image")
plt.subplot(2,3,5)

plt.show()

plt.show()

(h,v) = img.shape[:2]
center = (v / 2, h / 2)
angle = 500
scale =1.0
rotation_matrix = cv2.getRotationMatrix2D(center, angle, scale)
rotated_image = cv2.warpAffine(img, rotation_matrix, (v, h))
plt.imshow(cv2.cvtColor(rotated_image,cv2.COLOR_BGR2RGB))
plt.title("Rotated image")
plt.show()
center = (311,240)
angle = 10
scale =1.0
rotation_matrix = cv2.getRotationMatrix2D(center, 30,1)
rotated_image = cv2.warpAffine(img, rotation_matrix, (v,h))
shear_matrix = np.array([[1, 0.5, 0], [0, 1, 0]], dtype=np.float32)
sheared_image = cv2.warpAffine(img, shear_matrix, (v, h))
plt.figure(figsize=(12, 8))
plt.subplot(2,3,1),plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB)),plt.title("Original image")
plt.subplot(2,3,2),plt.imshow(cv2.cvtColor(rotated_image,cv2.COLOR_BGR2RGB)),plt.title("Rotated image")
plt.subplot(2,3,3),plt.imshow(cv2.cvtColor(sheared_image,cv2.COLOR_BGR2RGB)),plt.title("Sheared image")
plt.subplot(2,3,4),plt.imshow(cv2.cvtColor(img_scale,cv2.COLOR_BGR2RGB)),plt.title("Scaled image")
plt.subplot(2,3,5),plt.imshow(cv2.cvtColor(translated_image,cv2.COLOR_BGR2RGB)),plt.title("Translated image")
plt.subplot(2,3,6),plt.imshow(cv2.cvtColor(img_output,cv2.COLOR_BGR2RGB)),plt.title("Perspective image")
plt.tight_layout()
plt.show()

(h,v) = img.shape[:2]
center = (v / 2, h / 2)
angle = 500
scale =1.0


plt.show()
center = (311,240)
angle = 10
scale =1.0
rotation_matrix = cv2.getRotationMatrix2D(center, 30,1)
rotated_image = cv2.warpAffine(img, rotation_matrix, (v,h))
shear_matrix = np.array([[1, 0.5, 0], [0, 1, 0]], dtype=np.float32)
sheared_image = cv2.warpAffine(img, shear_matrix, (v, h))
plt.figure(figsize=(12, 8))
plt.subplot(2,3,1),plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB)),plt.title("Original image")
plt.subplot(2,3,2),plt.imshow(cv2.cvtColor(rotated_image,cv2.COLOR_BGR2RGB)),plt.title("Rotated image")
plt.subplot(2,3,3),plt.imshow(cv2.cvtColor(sheared_image,cv2.COLOR_BGR2RGB)),plt.title("Sheared image")
plt.subplot(2,3,4),plt.imshow(cv2.cvtColor(img_scale,cv2.COLOR_BGR2RGB)),plt.title("Scaled image")
plt.subplot(2,3,5),plt.imshow(cv2.cvtColor(translated_image,cv2.COLOR_BGR2RGB)),plt.title("Translated image")
plt.subplot(2,3,6),plt.imshow(cv2.cvtColor(img_output,cv2.COLOR_BGR2RGB)),plt.title("Perspective image")
plt.tight_layout()
plt.show()

import cv2
import numpy as np
from google.colab.patches import cv2_imshow
img=cv2.imread('/content/download.png')
import matplotlib.pyplot as plt
from google.colab import files
uploaded = files.upload()
filename = next(iter(uploaded))
image = cv2.imread(filename)
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
_, thresh =cv2.threshold(gray,127,255,cv2.THRESH_BINARY)
contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
result = image.copy()
cv2.drawContours(result,contours,-1,(0,255,0),2)
cv2_imshow(result)
print(f"found(len contours)contours")
cv2_imshow(image)

import cv2
import numpy as np
from google.colab.patches import cv2_imshow
img = cv2.imread("/content/sample_data/desktop-wallpaper-royal-enfield-classic-350-bs6-orange-ember-price-specs-review-royal-enfield-orange-ember.jpg")
laplaction = cv2.Laplacian(img,cv2.CV_64F)
cv2_imshow(laplaction)

import cv2
from google.colab.patches import cv2_imshow
img = cv2.imread  ("/content/sample_data/desktop-wallpaper-royal-enfield-classic-350-bs6-orange-ember-price-specs-review-royal-enfield-orange-ember.jpg")
soblex = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=3)
cv2_imshow(soblex)
sobley = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=1)
cv2_imshow(sobley)

import numpy as np
from google.colab.patches import cv2_imshow
img = cv2.imread("/content/sample_data/desktop-wallpaper-royal-enfield-classic-350-bs6-orange-ember-price-specs-review-royal-enfield-orange-ember.jpg")
roberts_x = np.array([[1, 0], [0, -1]],dtype=np.float32)
roberts_y = np.array([[0, 1], [-1, 0]],dtype=np.float32)
edge_x = cv2.filter2D(img, -1, roberts_x)
edge_y = cv2.filter2D(img, -1, roberts_y)
edges = cv2.addWeighted(edge_x, 0.5, edge_y, 0.5, 0)
cv2_imshow(edges)

scarr_x = cv2.Scharr(img, cv2.CV_64F, 1, 0)
scarr_y  = cv2.Scharr(img, cv2.CV_64F, 0, 1)
scarr_combined = cv2.addWeighted(scarr_x, 0.5, scarr_y, 0.5, 0)
cv2_imshow(scarr_x)
cv2_imshow(scarr_y)
cv2_imshow(scarr_combined)

img =cv2.imread("/content/sample_data/desktop-wallpaper-royal-enfield-classic-350-bs6-orange-ember-price-specs-review-royal-enfield-orange-ember.jpg")
prewitt_x = np.array([[1, 0, -1], [1, 0, -1], [1, 0, -1]], dtype=np.float32)
prewitt_y = np.array([[1, 1, 1], [0, 0, 0], [-1, -1, -1]], dtype=np.float32)
edge_x = cv2.filter2D(img, -1, prewitt_x)
edge_y = cv2.filter2D(img, -1, prewitt_y)
edges = cv2.addWeighted(edge_x, 0.5, edge_y, 0.5, 0)
cv2_imshow(edges)

import cv2
from google.colab.patches import cv2_imshow
img = cv2.imread("/content/sample_data/desktop-wallpaper-royal-enfield-classic-350-bs6-orange-ember-price-specs-review-royal-enfield-orange-ember.jpg")
low_threshold = 75; high_threshold = 250
canny_edges = cv2.Canny(img,22,330)
cv2_imshow(canny_edges)

import cv2
import numpy as np
from google.colab.patches import cv2_imshow
imag= cv2.imread('/content/sample_data/desktop-wallpaper-royal-enfield-classic-350-bs6-orange-ember-price-specs-review-royal-enfield-orange-ember.jpg')
cv2_imshow(imag)
grey=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
cv2_imshow(grey,30,200)
contours, hierarchy = cv2.findcontours(canny,
                                       cv2.RETER_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
print("Number of contours" , len contours)
cv2_imshow(canny)

cv2.drawContours(imag, contours, -1, (0, 255, 0), 2)
cv2_imshow(imag)

import cv2
import numpy as np
from google.colab.patches import cv2_imshow
imag= cv2.imread('/content/sample_data/desktop-wallpaper-royal-enfield-classic-350-bs6-orange-ember-price-specs-review-royal-enfield-orange-ember.jpg')
cv2_imshow(imag)
grey=cv2.cvtColor(imag,cv2.COLOR_BGR2GRAY)
cv2_imshow(grey)
canny=cv2.Canny(grey,30,200)
cv2_imshow(canny)
contours, hierarchy = cv2.findContours(canny, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

print("Number of contours" , len(contours))
cv2_imshow(canny)

cv2.drawContours(imag, contours, -1, (0, 255, 0), 2)
cv2_imshow(imag)

for i, contour in enumerate(contours):
    area = cv2.contourArea(contour)
    perimeter = cv2.arcLength(contour, True)
    print(f"Contour {i+1}: Area = {area}, Perimeter = {perimeter}")

for contour in contours:
    x, y, w, h = cv2.boundingRect(contour)
    cv2.rectangle(imag, (x, y), (x + w, y + h), (0, 255, 0), 2)
    cv2_imshow(imag)